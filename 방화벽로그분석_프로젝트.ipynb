{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "방화벽로그분석_프로젝트.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mwAunpPH-UuM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19efe325-ab24-428e-d8e4-7ca2c99ec6d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/방화벽로그분석_프로젝트"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPVO8aKM9ZX0",
        "outputId": "6da34e47-2d4f-4b03-f2a9-392fad11980b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/방화벽로그분석_프로젝트\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import argparse\n",
        "import time\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv"
      ],
      "metadata": {
        "id": "BboivNMKgk5q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1JfzY_Kj9CpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be73c9ef-4ce1-434b-b5cf-f188178b3f0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Rdate,src_ip,dst_ip,Proto,src_port,dst_port,Action,src_country,dst_country',\n",
              " '20210410000018.64,154.58.159.102,103.177.12.42,6,52897,445,2,None,US']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "f = open('04_hashed.csv').read()\n",
        "f.splitlines()[0:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encoding(data_path):\n",
        "  df = pd.read_csv(data_path, encoding='cp949', index_col=False)\n",
        "  df = df.iloc[:, [1, 2, 6, 8]]\n",
        "  df = df.drop_duplicates(subset=None, keep='first', inplace=False)\n",
        "\n",
        "  # df['Action'].value_counts() # '2' 3251557, '1' 2543596, '0' 25157\n",
        "\n",
        "  df_data = df[df['Action'] == 0]\n",
        "  df_data.to_csv('data.csv')\n",
        "\n",
        "encoding('04_hashed.csv')"
      ],
      "metadata": {
        "id": "7wKEoAx8jBqS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('label.csv', header=0, names=['src_ip','dst_ip','Action','dst_country'])\n",
        "cls_name, _ = pd.factorize(df.Action, sort=True)"
      ],
      "metadata": {
        "id": "OPq3hnlV2pD2"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test_ = train_test_split(df, test_size=0.3)\n",
        "test, val = train_test_split(test_, test_size=0.33)\n",
        "\n",
        "print(len(train), len(test), len(val))\n",
        "\n",
        "train.to_csv('train.csv')\n",
        "test.to_csv('test.csv')\n",
        "val.to_csv('val.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-dy-to48pA_",
        "outputId": "0c8d2663-4d97-43ed-ecbe-80c1b163f8b6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2088032 599564 295308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['Action'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6heJJ8MxJVu",
        "outputId": "12ce3a76-79b0-490b-9961-d19e708a956d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    2074027\n",
              "1      14005\n",
              "Name: Action, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IPDataset(Dataset):\n",
        "\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        csv_path (string): Path to the csv file with annotations.\n",
        "        transform (callable, optional): Optional transform to be applied on a sample.\n",
        "    \"\"\"\n",
        "    def __init__(self, csv_path):\n",
        "\n",
        "        csv_path = os.path.expanduser(csv_path)\n",
        "        assert os.path.exists(csv_path), '%s not found' % csv_path\n",
        "\n",
        "        # read csv file\n",
        "        self.df = pd.read_csv(csv_path, header=0, names=['src_ip','dst_ip','Action','dst_country'])\n",
        "        self.df.cls_name, _ = pd.factorize(self.df.Action, sort=True)\n",
        "\n",
        "        self._num_of_classes = 2\n",
        "        self._len_of_dataset = len(self.df.cls_name)\n",
        "\n",
        "        le = preprocessing.LabelEncoder() #convert string label to int\n",
        "        le.fit(df.dst_country)\n",
        "        self.dst_coun = le.transform(df.dst_country)\n",
        "\n",
        "    def get_num_of_classes(self):\n",
        "        return self._num_of_classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._len_of_dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        src_ip, dst_ip, action, dst_country  = self.df.iloc[idx]\n",
        "        \n",
        "        s_ip = src_ip.split('.')\n",
        "        d_ip = dst_ip.split('.')\n",
        "\n",
        "        dst_c = self.dst_coun[idx]\n",
        "\n",
        "        data = s_ip + d_ip + [dst_c]\n",
        "        label = action\n",
        "\n",
        "        # normalization\n",
        "        if action == 1:\n",
        "          label = 0\n",
        "        elif action == 2:\n",
        "          label = 1\n",
        "\n",
        "        data = [int(x) for x in data]\n",
        "\n",
        "        data = np.array(data) \n",
        "        labels = np.array(label)\n",
        "\n",
        "        # list -> numpy array -> torch array\n",
        "\n",
        "        return torch.from_numpy(data), torch.from_numpy(labels)"
      ],
      "metadata": {
        "id": "1GtAYk9o9keT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_csv = 'train.csv'\n",
        "test_dataset_csv = 'test.csv'\n",
        "\n",
        "IP_train_dataset = IPDataset(csv_path=train_dataset_csv)\n",
        "IP_test_dataset = IPDataset(csv_path=test_dataset_csv)\n",
        "\n",
        "for step, (data, label) in enumerate(IP_train_dataset):\n",
        "    print(data, label)\n",
        "    break"
      ],
      "metadata": {
        "id": "V4fXxEEq-B9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc47aa3f-ac0e-4773-d873-e120a36f6800"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 12, 150, 252, 150, 180, 184, 111,   1, 224]) tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, 32)\n",
        "        self.linear2 = torch.nn.Linear(32, 16)\n",
        "        self.linear3 = torch.nn.Linear(16, outputSize)\n",
        "        self.s = nn.Sigmoid()\n",
        "        # sigmoid -> [0,1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        out = self.linear2(out)\n",
        "        out = self.linear3(out)\n",
        "        out = self.s(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "6r26PmibAwES"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_dataloader = DataLoader(IP_train_dataset, batch_size=batch_size, num_workers=8)\n",
        "test_dataloader = DataLoader(IP_test_dataset, batch_size=batch_size, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo9bVoGLEX3k",
        "outputId": "a5dcd282-4bc2-4ed6-9b65-a544f5d8ccf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputDim = 9 # takes variable 'x' \n",
        "outputDim = 1 # takes variable 'y'\n",
        "learningRate = 0.001 \n",
        "num_of_epochs = 3\n",
        "batch_size = 512\n",
        "\n",
        "model = linearRegression(inputDim, outputDim)\n",
        "\n",
        "##### For GPU #######\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = torch.nn.MSELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
      ],
      "metadata": {
        "id": "5zrnG2DnByLJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_of_epochs):\n",
        "  model.train()\n",
        "  running_loss, running_corrects, total = 0, 0, 0\n",
        "\n",
        "  p_bar = tqdm(total=len(train_dataloader))\n",
        "  for step, (data, label) in enumerate(train_dataloader):\n",
        "\n",
        "      data = data / 1.0 \n",
        "      label = label / 1.0\n",
        "      \n",
        "      data = data.to(device)  \n",
        "      label = label.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      with torch.set_grad_enabled(True):\n",
        "          # diff\n",
        "          outputs = model(data)\n",
        "          loss = criterion(outputs, label)\n",
        "          loss.backward() #back prop\n",
        "          optimizer.step()\n",
        "\n",
        "      preds = (outputs>0.5).float()\n",
        "      lb = torch.reshape(label, (data.size(0), 1))\n",
        "      # print(label.data)\n",
        "      # print(preds)\n",
        "      # print(lb)\n",
        "\n",
        "      s = torch.sum(preds == lb.data)  \n",
        "      # print(s) \n",
        "\n",
        "      running_corrects += s\n",
        "\n",
        "      total += data.size(0)\n",
        "      running_loss += loss.item() * data.size(0)\n",
        "      _loss = float(running_loss) / total\n",
        "      _accu = float(running_corrects) / total * 100\n",
        "\n",
        "      p_bar.set_description('[TRAIN on Epoch #{:d} Loss: {:.4f} acc: {:.2f}%]'.format(epoch + 1, _loss, _accu))\n",
        "      p_bar.update(1)\n",
        "\n",
        "  p_bar.close()\n",
        "\n",
        "  model.eval()\n",
        "  running_loss, running_corrects, total = 0, 0, 0\n",
        "  p_bar = tqdm(total=len(test_dataloader))\n",
        "\n",
        "  for step, (data, label) in enumerate(test_dataloader):\n",
        "\n",
        "    data = data / 1.0 \n",
        "    label = label / 1.0\n",
        "\n",
        "    data = data.to(device)  \n",
        "    label = label.to(device)\n",
        "        \n",
        "    with torch.set_grad_enabled(False):\n",
        "      outputs = model(data)\n",
        "      loss = criterion(outputs, label)\n",
        "      preds = (outputs>0.5).float()\n",
        "        \n",
        "    # statistics\n",
        "    lb = torch.reshape(label, (data.size(0), 1))\n",
        "    # print(label.data)\n",
        "    # print(preds)\n",
        "    # print(lb)\n",
        "\n",
        "    s = torch.sum(preds == lb.data)  \n",
        "    # print(s) \n",
        "\n",
        "    running_corrects += s\n",
        "\n",
        "    total += data.size(0)\n",
        "    running_loss += loss.item() * data.size(0)\n",
        "    _loss = float(running_loss) / total\n",
        "    _accu = float(running_corrects) / total * 100\n",
        "\n",
        "    p_bar.set_description('[TEST on Epoch #{:d} Loss: {:.4f} acc: {:.2f}%]'.format(epoch + 1, _loss, _accu))\n",
        "    p_bar.update(1)\n",
        "        \n",
        "  p_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t39hpWDEsXn",
        "outputId": "9b126994-d012-4393-968c-18c9ad28d979"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/4079 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[TRAIN on Epoch #1 Loss: 0.0067 acc: 99.33%]: 100%|█████████▉| 4077/4079 [07:16<00:00, 11.72it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[TRAIN on Epoch #1 Loss: 0.0067 acc: 99.33%]: 100%|██████████| 4079/4079 [07:16<00:00,  9.34it/s]\n",
            "[TEST on Epoch #1 Loss: 0.0067 acc: 99.33%]: 100%|█████████▉| 1170/1172 [02:01<00:00, 16.46it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[TEST on Epoch #1 Loss: 0.0067 acc: 99.33%]: 100%|██████████| 1172/1172 [02:01<00:00,  9.66it/s]\n",
            "[TRAIN on Epoch #2 Loss: 0.0067 acc: 99.33%]: 100%|██████████| 4079/4079 [07:02<00:00,  9.67it/s]\n",
            "[TEST on Epoch #2 Loss: 0.0067 acc: 99.33%]: 100%|██████████| 1172/1172 [02:00<00:00,  9.75it/s]\n",
            "[TRAIN on Epoch #3 Loss: 0.0067 acc: 99.33%]: 100%|██████████| 4079/4079 [07:04<00:00,  9.62it/s]\n",
            "[TEST on Epoch #3 Loss: 0.0067 acc: 99.33%]: 100%|██████████| 1172/1172 [01:59<00:00,  9.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'models/model.ckpt')"
      ],
      "metadata": {
        "id": "LBCCPM1iaboi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "\n",
        "val_dataset_csv = 'val.csv'\n",
        "\n",
        "IP_val_dataset = IPDataset(csv_path=val_dataset_csv)\n",
        "val_dataloader = DataLoader(IP_val_dataset, batch_size=batch_size, num_workers=8)"
      ],
      "metadata": {
        "id": "htJfuCD4Ci0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b49df2-4010-4cfe-ab62-97ece7864438"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "running_loss, running_corrects, total = 0, 0, 0\n",
        "p_bar = tqdm(total=len(val_dataloader))\n",
        "\n",
        "for step, (data, label) in enumerate(val_dataloader):\n",
        "\n",
        "  data = data / 1.0 \n",
        "  label = label / 1.0\n",
        "\n",
        "  data = data.to(device)  \n",
        "  label = label.to(device)\n",
        "      \n",
        "  with torch.set_grad_enabled(False):\n",
        "    outputs = model(data)\n",
        "    loss = criterion(outputs, label)\n",
        "    preds = (outputs>0.5).float()\n",
        "      \n",
        "  # statistics\n",
        "  lb = torch.reshape(label, (data.size(0), 1))\n",
        "  # print(label.data)\n",
        "  # print(preds)\n",
        "  # print(lb)\n",
        "\n",
        "  s = torch.sum(preds == lb.data)  \n",
        "  # print(s) \n",
        "\n",
        "  running_corrects += s\n",
        "\n",
        "  total += data.size(0)\n",
        "  running_loss += loss.item() * data.size(0)\n",
        "  _loss = float(running_loss) / total\n",
        "  _accu = float(running_corrects) / total * 100\n",
        "\n",
        "  p_bar.set_description('[VAL on Epoch #{:d} Loss: {:.4f} acc: {:.2f}%]'.format(epoch + 1, _loss, _accu))\n",
        "  p_bar.update(1)\n",
        "      \n",
        "p_bar.close()"
      ],
      "metadata": {
        "id": "A0agXYRkDvH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7841140-d1f1-4e2f-b1e8-521a76160c80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/577 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([512])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[VAL on Epoch #3 Loss: 0.0065 acc: 99.35%]: 100%|█████████▉| 575/577 [00:59<00:00, 10.67it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([396])) that is different to the input size (torch.Size([396, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[VAL on Epoch #3 Loss: 0.0065 acc: 99.35%]: 100%|██████████| 577/577 [00:59<00:00,  9.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dataset_csv = 'data.csv'\n",
        "\n",
        "IP_data_dataset = IPDataset(csv_path=data_dataset_csv)\n",
        "data_dataloader = DataLoader(IP_data_dataset, batch_size=batch_size, num_workers=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab6k7-LAnTgh",
        "outputId": "a1fe91dc-6ff6-4f1a-89fb-0fd89f6a9a5d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "running_loss, running_corrects, total = 0, 0, 0\n",
        "p_bar = tqdm(total=len(data_dataloader))\n",
        "\n",
        "for step, (data, label) in enumerate(data_dataloader):\n",
        "\n",
        "  data = data / 1.0 \n",
        "  label = label / 1.0\n",
        "\n",
        "  data = data.to(device)  \n",
        "  label = label.to(device)\n",
        "      \n",
        "  with torch.set_grad_enabled(False):\n",
        "    outputs = model(data)\n",
        "    loss = criterion(outputs, label)\n",
        "    preds = (outputs>0.5).float()\n",
        "      \n",
        "  # statistics\n",
        "  lb = torch.reshape(label, (data.size(0), 1))\n",
        "  # print(label.data)\n",
        "  print(preds+1)\n",
        "  # print(lb)\n",
        "\n",
        "  s = torch.sum(preds == lb.data)  \n",
        "  # print(s) \n",
        "\n",
        "  running_corrects += s\n",
        "\n",
        "  total += data.size(0)\n",
        "  running_loss += loss.item() * data.size(0)\n",
        "  _loss = float(running_loss) / total\n",
        "  _accu = float(running_corrects) / total * 100\n",
        "\n",
        "  p_bar.set_description('[DATA on Epoch #{:d} Loss: {:.4f} acc: {:.2f}%]'.format(epoch + 1, _loss, _accu))\n",
        "  p_bar.update(1)\n",
        "      \n",
        "p_bar.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChBK4w6TnUZB",
        "outputId": "60e7d5a5-d426-4541-de25-09a18f3268a9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([37])) that is different to the input size (torch.Size([37, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "[DATA on Epoch #3 Loss: 1.0000 acc: 0.00%]: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [2.]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[DATA on Epoch #3 Loss: 1.0000 acc: 0.00%]: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n"
          ]
        }
      ]
    }
  ]
}